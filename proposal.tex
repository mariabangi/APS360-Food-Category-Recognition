\documentclass[final]{article}


\usepackage{aps360}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{graphicx}       % to import images
 
\title{Food Category Recognition}

\author{%
  Maria Bangi \\
  1010361519, maria.bangi@mail.utoronto.ca\\
  GitHub: \url{https://github.com/mariabangi/APS360-Food-Category-Recognition}\\
}

\begin{document}

\maketitle

\vspace{-0.5in}

\section*{Introduction}
Food recognition has become increasingly important as applications such as health and diet monitoring become more mainstream, restaurant and delivery services become automated, and accessibility tools are developed for impaired individuals. Accurate classification of food images enables calorie estimations, nutritional analysis, and improved user interaction. This is challenging due to large visual variations and similarities within food categoeries complicating classifications.

This project aims to develop a deep learning model that will classify food images into five broad food categories using a convolutional neural network (CNN) trained on the Food-101 dataset \cite{kaggle2025}. Future integration of the model will be nutritional applications that will automatically identify food categories and calorie intake from user-uploaded images.

\section*{Illustration}
The figure below illustrates the architecture of the food category recognition system. Food image inputs are preprocessed and sized before being passed into a CNN that extracts visual features through multiple convolutional and pooling layers. They are flattened and passed through fully connected layers to then have a final output as a probability distribution over the predefined food categories.

\begin{figure}[!h]
  \centering
  \includegraphics[width=0.95\linewidth]{figures/FoodRecognitionModel_Diagram.png}
  \caption{The CNN architecture for food category classification.}
  \label{fig:FoodRecognitionModel}
\end{figure}

\section*{Background \& Related Work}
Deep learning for food recognition has been widely studied in both computer vision and dietary assessment research. One of the most commonly used benchmarks within food recognition is the Food-101 dataset containing 101 different food categories, highlighting challenges in visual variations \cite{kaggle2025}. Early methods of deep learning used colours and shapes for identification and had limited success. With the introduction of CNNs, the approaches had a shift to multitask learning and lightweight learning \cite{mdpi2025}. Deep learning approaches such as Deep Food demonstrated that CNNs were able to significantly improve food recognition accuracy while identifying various food categories in one image and enabling future applications such as calorie estimation \cite{labellerr2025}.

Modern CNN architectures, such as ResNet, introduced layered residual connections that would stabilize training and allow the models to achieve strong performance with classification \cite{sciencedirect2023}. EfficientNet and MnasNet were later used to scale network depth, width and resolution to improve accuracy and make it cost manageable \cite{sciencedirect2023}. Recent models have compared the trade-off between traditional machine learning techniques and deep learning models. The models were then researched in web and mobile based application, where calorie and nutritional facts were assessed \cite{iop2021}. The research motivates the use of a 2-layer CNN-based classifier for robust food category recognition and supports the future implementation of the model.

\section*{Data Processing}
The Food-101 dataset will be used for training, as used in previous models \cite{kaggle2025}. The full data set allows for 101 food categories and a robust image set. To ensure that processing remains feasible, categories will be cut to five broad groups (Sandwich, Pizza, Pasta, Grains, Dessert). All images will be resized to a fixed resolution (224Ã—224) and converted to RGB format for consistent inputs.

The chosen data set will be split into both training (80\%) and validation (20\%) sets to ensure class balance. Pixel values will be normalized using the standard ImageNet statistics. Data augmentation techniques such as cropping, flipping and colour adjustments will be applied to improve the lighting and interview variations. Any corrupted images that are unreadable will be removed during pre-processing, so the image is not input for training, and data quality is improved through error prevention.

\section*{Architecture}
A CNN implemented in PyTorch using transfer learning will be used. A pretrained backbone may be incorporated, such as ResNet or EfficientNet, if feasible within the course scope. From existing models, the final classification layer will be replaced with a new fully connected layer that will output probabilities for the top food categories as the output. A softmax function will be applied to produce class probabilities, and as a result, training will use cross-entropy loss.

The model will initially be trained by iteration of fine-tuning the final layers, and additional layers may be implemented or unfrozen as full fine-tuning occurs for improved performance. If time permits, an extension of a transformer-based model based on existing models \cite{mdpi2025} to compare performance against the CNN approach when looking at visually similar food categories.

\section*{Baseline Model}
The baseline model will use a logistic regression classifier that is trained on HOG descriptors that are extracted from down-sampled images, similar to the CNN Architecture. The baseline model does not learn hierarchical visual features and is expected to provide a reference point for evaluating the benefit of deep learning and our CNN model.

\section*{Ethical Considerations}
Ethical concerns in food recognition lie in incorrect predictions that may influence health and dietary decisions. Misclassifications by the CNN could lead to inaccurate calorie and nutritional estimates, potentially harming users with restrictions or medical conditions. In addition, training data may be biased towards cuisine styles and presentation, reducing accuracy for underrepresented foods.

Privacy concerns arise as food images may contain personal information such as faces, locations, or receipts. Any future deployment should minimize image storage and communicate how any user data is handled. The system should be used as a tool rather than a source of medically accurate advice.

\newpage
\section*{References}
\renewcommand{\refname}{}
\bibliographystyle{unsrt}
\bibliography{bibliography}


\end{document}
