\documentclass[final]{article}


\usepackage{aps360}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{graphicx}
 
\title{Food Category Recognition}

\author{%
  Maria Bangi \\
  1010361519, maria.bangi@mail.utoronto.ca\\
  GitHub: \url{https://github.com/mariabangi/APS360-Food-Category-Recognition}\\
}

\begin{document}

\maketitle

\vspace{-0.5in}

\section*{Introduction}
Food recognition software has become increasingly important as applications such as health and diet monitoring become more mainstream, restaurant and delivery services become automated, and accessibility tools are developed for impaired individuals. The ability to accurately categorize food from photographs enables further analysis through calorie estimations, nutritional benefits, and overall improved user interactions on food-related apps and websites. The goal of this project is to develop a deep learning model that will classify food images into predetermined food categories such as 'pizza' and 'pasta'.   

This task is challenging as the visual variations of the food categories heavily differ even within one category of food due to food customizations; contrarily, foods from different categories also look similar in visuals. Small differences in lighting, food presentation, aesthetics and viewpoints all drastically change the food's imagery. Deep learning, through convolutional neural networks (CNN's), has previously demonstrated a strong performance on image classification by its ability to automatically learn significant visual features from raw pixel data given. For this reason, a CNN-based deep learning approach will be suitable and an effective method for food category recognition. This project will aim to train and evaluate a model to then integrate into a future nutritional application that will automatically identify food categories and calorie intake from user-uploaded images.

\section*{Illustration}
The figure below illustrates the architecture of the food category recognition system. Food image inputs are preprocessed and sized before being passed into a CNN that extracts visual features through multiple convolutional and pooling layers. They are flattened and passed through fully connected layers to then have a final output as a probability distribution over the predefined food categories.

\begin{figure}[!h]
  \centering
  \includegraphics[width=0.95\linewidth]{figures/FoodRecognitionModel.png}
  \caption{Figure 1: The CNN architecture for food category classification.}
  \label{fig:FoodRecognitionModel}
\end{figure}

\section*{Background \& Related Work}
Deep learning for food recognition has been widely studied in both computer vision and dietary assessment research. One of the most commonly used benchmarks within food recognition is the Food-101 dataset contained 101 different food categories, highlighting challenges in visual variations \cite{kaggle2025}. Early methods of deep learning used colours and shapes for identification and had limited success. With the introduction of CNNs, the approaches had a shift to multitask learning and lightweight learning \cite{mdpi2025}. Deep learning approaches such as Deep Food demonstrated that CNNs were able to significantly improve food recognition accuracy while identifying various food categories in one image and enabling future applications such as calorie estimation \cite{labellerr2025}.

Modern CNN architectures, such as ResNet, introduced layered residual connections that would stabilize training and allow the models to achieve strong performance with classification \cite{sciencedirect2023}. EfficientNet and MnasNet were later used to scale network depth, width and resolution to improve accuracy and make it cost manageable \cite{sciencedirect2023}. Recent models have compared the trade-off between traditional machine learning techniques and deep learning models. The models were then researched in web and mobile based application, where calorie and nutritional facts were assessed \cite{iop2021}. The research motivates the use of a 2-layer CNN-based classifier for robust food category recognition and supports the future implementation of the model.

\section*{Data Processing}
The dataset used for this project will be a publicly available food image dataset, Food-101 \cite{kaggle2025}, used in previous models. To match the goal of food recognition for a nutritional application, the full data set allows for 101 food categories and a robust image set. To ensure that data processing remains feasible, the dataset may be cut down to remove repetitive categories and reduce complexity to ensure sufficient samples per class. All images will be resized to a fixed resolution (~ 224Ã—224) and converted to RGB format for consistent inputs.

The chosen data set will be split into both training and validation sets to ensure class balance. Pixel values will be normalized using the standard ImageNet statistics. Data augmentation techniques such as cropping, flipping and colour adjustments will be applied to improve the lighting and interview variations. Any corrupted images that are unreadable will be removed during pre-processing, so the image is not input for training, and data quality is improved through error prevention.

\section*{Architecture}
The primary model used will be a CNN implemented in PyTorch using transfer learning. A pretrained backbone may be used like preexisting models, such as ResNet or EfficientNet, if feasible within the course scope. From existing models, the final classification layer will be replaced with a new fully connected layer that will output probabilities forthe  top food categories as the output. A softmax function will be applied to produce class probabilities, and as a result, training will use cross-entropy loss.

The model will initially be trained by iteration of fine-tuning the final layers, and additional layers may be implemented or unfrozen as full fine-tuning occurs for improved performance. If time permits, an extension of a transformer-based model based on existing models \cite{mdpi2025} to compare performance against the CNN approach when looking at visually similar food categories.

\section*{Baseline Model}
A simple baseline model will be implemented to help contextualize the performance of the learning model and comparisons. This will consist of a linear classifier (logistic regression/support vector machine) trained on image features such as HOG descriptors or down-sampled pixel values, similar to the CNN Architecture. The baseline does not learn hierarchical visual features and is expected to perform worse CNN; however, the comparison will demonstrate the benefits of the deep learning model.

\section*{Ethical Considerations}
Ethical concerns in food recognition lie in incorrect predictions that may influence health and dietary decisions. Misclassifications by the CNN could lead to inaccurate calorie and nutritional estimates, potentially harming users with restrictions or medical conditions. In addition, training data may be biased towards cuisine styles and presentation, reducing accuracy for underrepresented foods.

Privacy concerns arise as food images may contain personal information such as faces, locations, or receipts. Any future deployment should minimize image storage and communicate how any user data is handled. The system should be used as a tool rather than a source of medically accurate advice.

\newpage
\section*{References}
\bibliographystyle{unsrt}
\bibliography{bibliography}


\end{document}
